# 【10】資安的原罪 ch.3-1.a 單機電腦

## 🖥️ 1. Standalone Computers (1940s)

The first true electronic computer, **ENIAC (Electronic Numerical Integrator and Computer)**, was developed in the 1940s and marked a pivotal moment in computing history. It was a massive, room-sized machine capable of performing thousands of calculations per second.

At the time, users had to punch their programs onto physical cards and submit entire **batches** of these cards to system operators for processing — a slow and non-interactive experience.

---

## 🧠 2. The Stored-Program Concept (1945)

In 1945, **John von Neumann** proposed the **stored-program concept** in his report *“First Draft of a Report on the EDVAC.”* This model became the foundation of modern computing.

Key ideas:

* Both **program instructions** and **data** are stored in the same memory.
* The CPU fetches instructions just like it fetches data.
* Computers could be **reprogrammed** by loading new code into memory, removing the need for rewiring.

This innovation dramatically increased flexibility and paved the way for interactive computing.

---

## ⏱️ 3. Time-Sharing and CTSS (1961)

The **Compatible Time-Sharing System (CTSS)** was developed at MIT in 1961. It was one of the first operating systems that allowed **multiple users** to access a single computer **simultaneously** by dividing CPU time among users — a concept known as **time-sharing**.

This shift:

* Replaced slow batch processing.
* Enabled **interactive computing** through user terminals.
* Improved system resource utilization and user experience.

---

TODO:
## 🔐 4. Formal Models of Security

### 4.1 The Bell–LaPadula Model & the Basic Security Theorem (1970s)

Developed by **David Elliott Bell** and **Leonard J. LaPadula** for the U.S. Department of Defense, the **Bell–LaPadula model** is a formal **access control model** focusing on **confidentiality**.

#### Core Concepts:

* **Subjects**: users, processes
* **Objects**: files, databases
* **Security levels**: Unclassified, Confidential, Secret, Top Secret

#### Key Rules:

* **Simple Security Property (No Read Up)**: Users can’t read data above their clearance level.
* \***-Property (No Write Down)**: Users can’t write data to a lower clearance level.

TODO:
#### 🔒 Basic Security Theorem:

> **If a system starts in a secure state and all transitions preserve the security properties, the system remains secure.**

Mathematically:
**Secure Initial State + Secure Transitions ⇒ Always Secure**

TODO:
### 4.2 Formal Verification

Introduced formally in the **1983 U.S. Department of Defense “Orange Book”**, also known as the **Trusted Computer System Evaluation Criteria (TCSEC)**.

**Formal verification** is a mathematical method to prove that systems behave according to their specifications — especially in critical applications like military, medical, and aerospace systems.

---

## 難以解決的問題

### 5.1 Shared Memory for Code & Data: A Double-Edged Sword

The innovation of sharing memory between **code and data** increased efficiency but also introduced a major vulnerability:

> If the system cannot distinguish between “data to be processed” and “code to be executed,” malicious input can be **executed as code** — the foundation of many modern attacks.

To fix this would require a fundamental shift — such as **hardware-level separation** of code and data — which is rarely practical.

---

### 5.2 Covert Channels & the Confinement Problem
硬體物理的運作遵循物理的法則，隱密隧道的問題將永遠存在，而現在隨著行動運算、雲端運算的盛行，這將會是未來恐怕不德不在面對的問題
TODO: A49
**Covert channels** are unintended communication paths that bypass normal security controls — often leveraging hardware behavior.

* **Confinement Problem**: It’s impossible to guarantee that a program cannot leak data to the outside world.
* These channels **don’t rely on software vulnerabilities** and are difficult to detect or eliminate.

TODO:
As mobile and cloud computing become dominant, these threats become more serious.

---


### 5.3 Operating System Trust & Compiler Backdoors

TODO: Multics編譯器問題 湯普森不得不成親沒有將後門導入UNIX
All software must ultimately run on an **operating system**, which itself must be compiled — and **compilers can be subverted**.

* **Ken Thompson** (creator of UNIX) demonstrated in his famous talk *“Reflections on Trusting Trust”* how a compiler could insert a **backdoor** into any program it compiles — even into itself — in a way that is **invisible** to code reviewers.
* Unless you write **everything from scratch** (including your compiler), you can never fully trust your system.
* Real-world example: **Eric Allman’s `sendmail`** accidentally left in a backdoor that was later exploited by the **Morris Worm**.

---
TODO:
### 5.4 The Cost of Verified Security

While **mathematically verified security** is ideal, it is:

* **Time-consuming**
* **Expensive**
* Often **commercially unviable**

Example:
The **SCOMP computer**, one of the few systems to achieve **A1-level certification** (highest under TCSEC), sold fewer than **30 units** worldwide.
Meanwhile, only around **200 experts** globally are capable of evaluating software to that standard.


---

任何安全性努力忽視了作業系統的安全性，那就無異於把堡壘建在沙子上。

"The Inevitable Failure" (often referenced as "The Inevitability of Failure") is a seminal paper by P. Loscocco et al. published in 1998 that argues failure is a normal, unavoidable characteristic of complex computing systems


[^1]: https://ieeexplore.ieee.org/document/601735